{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72d26df0",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "## Chapter Overview\n",
    "In this chapter, we'll introduce PyTorch and its rich ecosystem, and learn how it can be used to tackle many different problems. We'll discuss the differences between supervised and unsupervised learning, and how machine and deep learning are different from traditional software development. Then, we'll go over a simple \"Hello Model\" example and talk about the sometimes challenging naming conventions used in our field.\n",
    "\n",
    "This chapter focuses on getting everyone on the same page to start their learning journey. By the end of it, you should have a general understanding of supervised learning, models, and the most common terms used in the field.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this chapter, you should be able to:\n",
    "\n",
    "* Discuss the difference between supervised and unsupervised learning\n",
    "* Discuss the difference between software development and machine and deep learning\n",
    "* Understand the general idea behind building and training a model\n",
    "* Identify commonly used terms in machine and deep learning and their meanings\n",
    "\n",
    "# PyTorch, Datasets, and Models\n",
    "\n",
    "## What Is PyTorch?\n",
    "PyTorch is an open-source deep learning framework developed by Meta AI in 2016. It offers both modularity and flexibility, making it a capable tool for everything from tinkering with innovative models to maintaining an industry-scale application.\n",
    "\n",
    "PyTorch can be used to solve many types of problems, but a good way to begin learning about PyTorch is to explore its ability to solve optimization problems. Let's say you'd like to estimate the fuel efficiency of cars based on their power and weight. You'll need data for this. PyTorch can help you develop a model that predicts the car's efficiency based on its power and weight. This would be a specific type of optimization problem called a linear regression model, and this model would be called a linear regression model. This is a simple problem that could be solved in Excel, but this makes it a useful thought experiment to begin wrapping your head around the sorts of problems PyTorch can solve.\n",
    "\n",
    "But, what about really complex problems? What if you have lots and lots of features (like hundreds or thousands of columns in a spreadsheet)? What if you have a humongous amount of data (picture millions of rows in a spreadsheet)? \n",
    "\n",
    "PyTorch uses an algorithm called gradient descent that is capable of looking for solutions regardless of how complex your problem is, or how massive the amount of data is. It starts from a random point and, little by little, works on improving the solution, one baby step at a time. This is performed by PyTorch's autograd module, which does the heavy lifting for you so you can focus on more interesting matters.\n",
    "\n",
    "\n",
    "## The PyTorch Ecosystem\n",
    "The range of fields and applications that can be powered by PyTorch is extensive:\n",
    "\n",
    "- Computer Vision (Kornia, Medical Open Network for Artificial Intelligence (MONAI), OpenMMLab, PyTorchVideo, Detectron2, PyTorch3D)\n",
    "    - machine and vehicular object detection, tracking, identification, and avoidance\n",
    "    - medical image analysis and diagnosis\n",
    "    - image recognition, classification, and tagging\n",
    "    - video classification and detection\n",
    "- Natural Language Processing (AllenNLP, NeMo, Transformers, flair)\n",
    "    - text classification, summarization, generation, and translation virtual assistants\n",
    "    - sentiment analysis\n",
    "    - question answering and search engines\n",
    "- Graph Neural Networks (torchdrug, PyTorch Geometric, DGL)\n",
    "    - molecule fingerprinting\n",
    "    - drug discovery and protein interface prediction\n",
    "    - social network analysis\n",
    "- Spatio-Temporal Graph Neural Networks (PyTorch Geometric Temporal)\n",
    "    - route planning and navigation\n",
    "    - traffic control and management\n",
    "    - inventory planning\n",
    "    - logistics optimization\n",
    "- Gaussian Processes (GPyTorch)\n",
    "    - time series modeling and anomaly detection\n",
    "    - risk management\n",
    "    - control engineering and robotics\n",
    "- Reinforcement Learning (PRFL)\n",
    "    - industry automation and robotics manipulation\n",
    "    - dynamic treatment regimes (DTRs) in healthcare\n",
    "    - real-time bidding\n",
    "    - strategy games\n",
    "* Recommender Systems (TorchRec)\n",
    "* Interpretability and Explainability (Captum)\n",
    "* Privacy-Preserving Machine Learning (CrypTen, PySyft, Opacus)\n",
    "* Federated Learning - collaboratively training a model without the need to centralize the data (PySyft, Flower)\n",
    "PyTorch has a very rich ecosystem of tools and libraries. From high-level libraries (e.g. PyTorch Lightning, fast.ai, Ignite, Catalyst, Skorch) that handle most of the boilerplate involved in developing and training models to highly-specialized ones (e.g. TorchDrug, ChemicalX) for drug discovery. There are supporting libraries to improve model interpretability (e.g. Captum) and ensure data privacy (e.g. PySyft) as well. In a nutshell, there are libraries and pre-trained models available for a wide range of topics and applications.\n",
    "\n",
    "## Hugging Face\n",
    "A discussion of the PyTorch ecosystem would not be complete without mentioning Hugging Face. While not a part of PyTorch, it is widely known for its large open-source community and is a central hub for models and Python libraries, especially in the area of natural language processing (NLP). Because it is so often used alongside PyTorch, it belongs in any discussion of the PyTorch ecosystem and we will make use of it in this course.\n",
    "\n",
    "## Supervised vs. Unsupervised Learning\n",
    "The majority of models and algorithms in machine and deep learning fall into one of these classes: supervised learning and unsupervised learning.\n",
    "\n",
    "To train a model using supervised learning is like actively teaching a toddler. You can show them a picture of a zebra and ask them what they see. They reply \"it's a horse\", because they've never seen a zebra before. You tell them it was a good guess, but the right answer is \"zebra\". You're supervising their learning by providing the right answer to every question. Hopefully, with enough examples and their corresponding answers, your model will also learn. Sometimes, though, you'll have to accept that the model you're training isn't powerful enough to tell a Chihuahua from a muffin:\n",
    "\n",
    " \n",
    "\n",
    "The image is a screenshot of a composite image of 16 photos of chihuahuas' faces and muffins, 8 photos of each. The images are funny because, at first glance, it is easy to mistake a Chihuahua's face for a muffin.\n",
    "\n",
    "Chihuahua or Muffin? Source: @teenybiscuit on Twitter\n",
    "\n",
    " \n",
    "\n",
    "Unsupervised learning, on the other hand, is like giving a toddler a bunch of building blocks and asking them to organize them without any specific instructions on how to do it. Maybe the toddler will split the blocks by color. Maybe they will split the blocks by size. It depends on which feature of the blocks, the color or the size, is more noticeable to them. Notice that you're not giving the toddler any \"right\" answers. It's exactly the same with these models and algorithms: they will look for similarities in the data, and use it to split it into groups. We won't be covering those in this course.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ec78ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab29f65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
